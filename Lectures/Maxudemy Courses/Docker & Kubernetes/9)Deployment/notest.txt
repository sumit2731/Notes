125)from dev to prod.
    see slide 2
    things to keep in mind -
        1) for bind mounts even though we may use them during development and we shouldn't use them in production.You will still learn
         in this section how does won't contradict the idea behind containers and how does won't lead to containers that are different 
         during development and production.
        
        2)your containerized apps might need different setups for development and for production which sounds strange at first
            after all the idea with containers was that we have one at the same environment.That's true but some applications
            like React apps for example simply need a build step where the code is converted and optimized and that builds step
            happens after development before you deploy the application.But even though we need this build step in this module
            you will all learn how you can still ensure that you ship containers which have reproducible environments and where 
            to code that work locally will also work once you deployed it

        3)So whilst you might be able to test everything let's say with Docker compose locally on one host machine for deployment you
         might consider splitting it across multiple servers or multiple host machines

        4)couple of lectures in this module where we will actually go for less control but also less responsibilities solution
            so that ultimately we as a developer have an easier time.


126)deployment processes and examples
    here we will deploy a simple nodejs application woth database to EC2 in aws.
    refer slide 4
        hosting provider - remote machine.


127)here we deploy a node js app without db into EC2.EC2 is a service offered by AWS which allows you to spin up your own remote hosting
    machines, you could say,Your own computers in the cloud.
    And we will go though three main steps to bring our Dockerized application to life on an EC2 instance.
        refer slide 6

    refer to code1 foler. first we build the image -
        docker build -t node-dep-example .

    then we run the container based on that image -

        docker run -d --rm --name node-dep -p 80:80 node-dep-example

128)bind mounts in prod
    refer slide 3. 
    while running container we did'nt specified any bind mounds infact we didi not use any volumes.

    In development so whilst we're working on the application,our container of course should encapsulate the runtime environment,but not 
    and that's important, not necessarily the code.

    In Prod ,There the idea really is that the container works standalone and that it does not depend on any surrounding setup on the 
    remote machine.The image and therefore the container based on the image should be the single source of truth you could say.That means
    we can rely on the fact that if we take that image and run a container based on it,we got everything this application needs.We don't 
    also need to move some source code into a special folder on that remote machine.That would totally destroy the idea behind containers
    if we now all of a sudden again need to configure the hosting machine.We want to have everything,what our application needs inside of
    that container.There should be nothing, absolutely nothing,around that container on the hosting machine.And therefore when we build for
    production,we use copy instead of bind mounts.


    now we specify bind mounts and volumnes while running a container based on a image. thsi helps us to use same docker imge in dev and
    prod, its just while running container for dev we can use bind mounts. this is the reason why bind mounts an dvolumes are not part of
    dockerFile.


    Now of course if we used a Docker compose file,we might have that bind mount written into that compose file,but I will come back to 
    compose files and how we deploy such multi container projects later.For the moment it's about one container, one image and then copy
    is your friend


129)Introducing AWS & EC2
    EC2 allows us to create virtual servers in cloud which means our own computers in cloud.  
    1)go to aws management console.
    2)search Ec2 and clicked on it.
    3)now goal is to start a Ec2 instance, there are multiplw ways of doing it.one is to click on "Launch Instance".

130)Connecting to an EC2 instance
    1)here we configure our instance that we are going to launch. 
    2)important screen is keypair.Here you can create a new key pair and you will need this key pair,which will be a file in the end,to 
        later connect to your instance via SSH and to run commands on it. so created a key pair and gave it name example-1.
    3)after creating key-pair, we clicked on Luanch instance.
    4)click on "view all instances".
    5)status of your instnace your be running.
    6)now we need to connect to this server using ssh.
        a)for mac and linux - 
            you can directly use ssh command in terminal.
        b)for windows this is not build it .
            a)you need to instal wsl2 on widnows 10(linux running for windows) or putty.

    7)select instnace and click on connect and select ssh. here follow the steps given in to connect to server.
    8)now we are connected to remote server.

131)Installing docker
    updating packages -
        sudo yum update -y
            this will update all packages. then run this -

    installing docker -
        sudo amazon-linux-extras install docker

        that's why we should pick this amaxon image when we created this instance.on this amazozn based virtual instances,we have these commands 
        avalible which makes installing these extra softwares like docker easier. this will install docker on remote machine.

    starting docker -
        sudo service docker start
        now docker is started and we can run docker commands.


133)pushing image to cloud

    step to publish image to docker hub -

        1)create repository on docker hub. name it - sumeet-node-example-27.
        2)create a image on your local machine whose ame is same as name of repository. -

            docker build -t node-dep-example-1 .
            docker tag node-dep-example-1 sumeet27/sumeet-node-example-27

        3)then login into docker hub -
            docker login
        4)docker push sumeet27/sumeet-node-example-27

134)RUNNING & PUBLISHING the app(on EC2)
    run this command to download and run your pushed image on ec2 instance -

        sudo docker run -d --rm -p 80:80 sumeet27/sumeet-node-example-27

    you can run this to cnfoirm if your container is running - sudo docker run -d --rm -p 80:80 sumeet27/sumeet-node-example-27

    now go to instance ;ist in ec2 list and copy the ip4 address fo your instance. hit tha address in browser. but we do not see anything.
    
    And that's not a bug, that's a security feature.By default, your instance your EC2 instance, is basically disconnected from everything
    in the world wide web, so that no one is able to connect except for you with SSH.And this is controlled with a so called security group.

    to chnage this, on left side go to "Security Groups" or in your instnace you can see security group, you can click on it and you will be
    taken to security group.security groups basically controls which traffic is allowed on our EC2 instance.
        outbound rules - controls which traffic is allowed from the instance queue to somewhere else
        inbound rules - controls which traffic is allowed form outside world to this instance. here only one port is open which is 22, this
            is for ssh. this port is open for entire world. now here we add a new role to inbound group. to allow outside world to access this
            port.

    now using IP you can see your websit via ip of EC2.


135)managing and updating the container /image
    here we saw how you could push updates to your code,to that remote server and how you can then stop and shut everything down if you want
     that to do that. 

    updating the code -

        1)make code chnages on local system.
        2)build the image on local.
            docker build -t node-dep-example-1 .
            docker tag node-dep-example-1 sumeet27/sumeet-node-example-27
        3)push the image on docker hub.
            docker push sumeet27/sumeet-node-example-27

        4)stop container on EC2 instance.

        5)pull latest image -
            docker pull sumeet27/sumeet-node-example-27
        5)rerun the container based on image -
            sudo docker run -d --rm -p 80:80 sumeet27/sumeet-node-example-27

    Stopping Everything -
        Way 1 -
            a)stop the container.

        way 2 -
            a)terminate ecs instance - select the instance, actions -> instance state -> terminate


        this will not be the final way of deploying an application with Docker.Because it turns out that this approach,which has showed 
        you in great detail here,has a couple of disadvantages and downsides.


136)Disadvantages of current approach - 
    see slide 9.

    disdavantges -
        1)You are responsible for security.
        2)You are responsible for updating OS.
        3)connecting to remote client via SSH can be cumbersome. we can have some approach where  wwe can run a single command where all this
            will be taken care of.

137)From manualdeployment to managed services
    ECS - elastic container service. it helps in managing container.With launching them, running them, monitoring them and so on.

    switching to some managed service,no matter if it's by AWS or by any other provider,means that you don't just use Docker anymore,
    instead, you now use a service provided by a cloud provider and you have to follow the rules of that service you could say.
    That simply means that deploying containers and running containers is now not done with the Docker command anymore because now we don't
    install Docker on some machine anymore that's the entire idea behind a managed service,but instead it means that we now will need to 
    use the tools the cloud provider gives us for the specific service we wanna use.

    here we will show this with the example of AWS ECS.It's just one possible example.
    I still wanna show you over the next lectures,how you could take what you learned and migrate that into the rule set
    a specific service gives you or forces on you and therefore these steps shown there will only work for that service.

139)Deploying with AWS ECS: A managed Docker container Service.

    here we want to run our container based on image pushed in docker hub via ECS. AWS ECS things in 4 categories -

    a)clusters
    b)containers
    c)tasks
    d)service

    containaer -
        lets start with container. we pick the container that want to deploy. there are some examples but we pick the custom one,
        so we should configure it. we click on configure and sidebar opens.here we configure howw ECS later executes "docker run".  it means
        all this options can we configure when we execute "docker run" command -
        here we give -

            name of container
            image based on which it should run
            port that should exposed

            in env section -
                entry point or command that should be xecuted wjen this container starts.
                working directory -

                envirenment variavles

            network settings - will come back to this when we have more than one container deployed.By default, our container will be 
                reachable from the web.

            storage and loggings - we can define bind mounts and volumes.

        now we defined our container that should be launched form here.

    tasks -
        Now, in the next section, we can define our task for this container.And the task is basically, as it says here,the blueprint for 
        your application.Here, you can tell AWS how it should launch your container.So not how it should execute docker run,but how the 
        server on which it runs this should be configured, you could say.And therefore a task actually also can include more than one 
        container.options here -

            compatibility - fargate or EC2.

        leave it untouched.

    service - And a service, in the end, now controls how this task,so this configured application and the container
        that belongs to it, should be executed. options -

        load balancer - we will not use it now.

        So you could say every task is executed by a service.So you have one service per task.

    cluster - 
        You could say that's the overall network in which our services run.Here, we have just one service with one task with one 
        container,but if you had a multi-container app,you could group multiple containers in one cluster so that they all belong together 
        logically, and they all can talk to each other.Now here, we automatically get this cluster network created for us


    after setting all these click on create , then on "view Service". now created service will be openen. how to see our running application -

        1)click on tasks. then click on single task(taskid not task defination).
        2)there under network, you can find public IP. paste this in browser and you will see your app up and running.

    but the huge advantage here is that we didn't start any custom servers or machines.We did not install anything, and we're not responsible
    for keeping anything up to date. We just configured how AWS should execute our containers,and that is it.


141)Updating managed container

    update your image and push it to docker hub. ow how to tell ECS to download the updated service -

        1)got to clusters -> default -> task -> task defination -> create new revision

            create new revision creates new task, keep all seetings same because we just want to create same task again.ECS will pull image form docker hub when you create
            a new task and then launch and use service in that tasks.

        2)click on "create" -> actions -> update service -> skip to review -> update service.

        3)now go to service -> tasks -> click on task id -> public ip -> open it in browser.

        now you will see that ip has chnaged, But there are ways of actually still connecting a domain to this running ECS task in general,
        independent from the specific IP AWS assigned,more on that can be found in the resources attached to this lecture.



    alternate -
        do niot create new task , under culster, open service -> update servicde -> select "Force new deployment"


142)Preparing a multiContainer App
    delete the previous setup -
        delete the service in cluster
        then delete the cluster


    refer to code 2. here we have 2 containers via docker compose.

    Important things -

        a)we will not use docker compose for deployment.Docker compose is a great tool for running multiple containers in a Docker
        compose file,possibly also for multiple containers on your local machine.But it's not really a great tool for deployment 
        right now. on deployment certain things start to matter which were not there in local like how CPU should be allocated to
        particular service.It depends heavily on the hosting provider you're using,which kind of extra information might be 
        needed. as this info cnt be part of docker compose.But that's no problem,you will see that deploying these individual 
        containers will still be super easy.And that we can use this compose file as an inspiration. To understand which deployment
        settings are needed for aws.So therefore, we'll just use docker-compose config file ,you could say an inspiration of what 
        we need to do and manually deploy these individual containers,these services to AWS ECS.

        b)Unfortunately for AWS ECS we will not be able to use this automatic find the container IP by container name feature
        which works so nice locally. this is because on local system, all contianer runs on same machine and docker creates the 
        network , all container are put on this network on same machine.and docker is able to replace the placeholder with actualt 
        IP of contianer. but on ECS there are thiusands of machine. it is highly unlikely that both your container will run on same
        machine.

        however if we use same task for them then they will run on same machine, Still then AWS ECS will not create a Docker network
        for them instead it allows you to use localhost as an address inside of your container application code.



        And you create a Docker network and then all these containers will be put into the same network on your local machine.
        And then AWS ECS gives us access to the network on that machine and to the other containers,which are part of the task,
        through the local host address.


        So we can use localhost instead of Mongo DB here when deploying this with AWS ECS,because these two containers,which we 
        wanna connect the node app container and Mongo DB will be part of the same task,and therefore will be guaranteed to run
        on the same machine.And then AWS ECS gives us access to the network on that machine and to the other containers,which are
        part of the task,through the local host address.

        but we do not want to change code when we deply i local and prod. for that we used value of mongodb from env file.
        for dev we give this value to MONGODB_UR in backaend.env.



143)configuring nodejs backend container

    here we created cluster, then we created task within that cluster.
    to create task we created task definations, within task definations we confgued the container.

     here while cretaing container ,under envirement tab added some configurations -

        a)commad - node,app.js
            this is because in local we run "npm start", which means => "start": "nodemon app.js"

            in prod we do not have dev dependeny nodemon and we do not want live reloading so overwrite command given in docker file
            give our own command.
        b)then under envirement variables we have value to env variables.
     
144)Deploying a Second Container & A Loadbalancer

    hHere under same task defination we add a another container.as a image we add official mongo image. but for mongo container, in 
    local we used a bind mount to persisten data. for time being in ECS container we leave the volumes part empty, we will
    revisist this later.


    so we add the container under same task defination. so we have a task defination with 2 contaner inside of it.
    With that created,we can now launch a service based on this task,which then actually launches these containers
    with the defined configuration.

    for that go to clusters, then open our cluster, then go to services.



145)Using load balancer for stable domain

    mistake made -
        a)in target group, under group_settings -> helathcheck ->  api call was sent to / for health check, as result containers were restarted frequenlt.
        b)in load balancer only default security group was added, goals security grouo(which is used for ECS services) was not added.

        now you can use the url given in loadbalancer page to access your pages by domain.


146)Using EFS Volumes with ECS
    here data was not persistent when our task was shut down. we went to our task and under volumne we added a EFS(elastic file 
    system)EFS helps us to add hard drive to our server less container which will survive even if container shuts down.

    we updated the task defination and created a volume inside it.type of volume is EFS.EFS is aws services which helps to attach 
    file syste to containers. this file system will survive even ifcontainers are restarted.
     
    intially there is no file system that we can attach. 
    
        so we create a filesystem via AFS console, and while creating it we 
        configure it -
            1)we crated a new security group while configuring the file system.
            2)In security group create a new inbound rule -
                type -BFS
                Source - selecet custome , then select securty group of EFS that you are using for containers.
                
                    this allows container running in group1 to talk with anything in newly secity group over a configured port.

            3)in network access section add this securoty group.

    then we select this newly created file system while adding volume in our  task defination. this is same as defining the volume
    at the end of docker-compose file. now go to container inside tasks and under mound poiints select this volume and map it
    to the location inside container. now click on container to create new task revioson.

    now action -> update service(force redeployment)

    now when we restart the service, we will see that we our new deployment is not succesful and under tasks in services there are
    failed tasks. read logs reason is that we are using rolling deployment, older instance will be killed when new isntance is 
    started. as result new isntance is not started. so we manually kill ur task in service , so that new task is started automatically.


    we are happu with this workaround because anyway we will be relacing this mongodb container with other strategy.


147)Our Current Architecture

    refer to slide 12 to see current architecture.


148)Databases & Containers:Important considerations
    refer to slide 11 for problem in db containers
    
149)Moving to mongoDb atlas
    here we moved to cloud based mngo db service - mongo atlas

152)Understanding common problem

    here we saw problem that in UI for prod we need separate command to build application then need a server to serve it.

153)cretaing build only container

    here we created a new docker file Dockerfile.prod, with configs only for prod. we ran build command insted of npm start.
    but we also need a server to serve these file. for that lets have a look at multi stage builds.

154)
    see slide 17. here we had a look at multi stage builds or multi stage docker files.

    with multistage builds we need use run instead of commands. so we chnage ourr docker file. so our first step is to generate 
    build files.

    Then we can continue with more steps thereafter.Now, we could do it as in a regular Dockerfile as well.But now here's the 
    special thing,I wanna switch to a different base image after this command.

    We can have a second FROM statement here, effectively turning this into a multi-stage build Dockerfile.Because typically, you
    must only have one base image. see notes in Dockerfile.prod in frontend folder.

    at the end of lecture our multi stage DockerFile is ready, now lets see how can we use this file.

155)Building a Multi Stage Image

    see dockerFile of frontend folder in code 3. 

    here we build our docker forntend docker image -

    docker build -f frontend/Dockerfile.prod -t academind/goals-react ./frontend


    here you can see that we gave frontend path 2 times. with frontend at lst we set the context for build coomand and  at begining
    we give it point to our DockerFile. see the DockerCompose.yaml file in docker compose section to know this context thing.

    after build we pushed it into docker hub.


156)Deploying a standalone frontend app

    we go to our task definations, then open task for this app. then open latest revision and then click on 
    "create new task revision".then in container defination part we added a new container.

    here while configuring container, we configured the "startup dependeny ordering" i.e backend should start first.

    but create button was dsiabled as both container were uisng same port. solutions -
        a)both backend and frotned can be part of same container. and same node server ca serve our html also.
        b)we can use diffrent port for backend.
        c)we can create separate rask for frotned.

    for sake of showing how to host multiple containers we go wth solution 3. so we did this -
    we created new tasks defination.
    create new loadbalancer
    view the task defination and go to actions -> create a service.
    create the service based on this task,and then add a loadBalancer in service.

    In your FE code use the url from load balancer of backend(load balancer is configured in service)and use that in your code.
    in code we added a condition to use local host the its dev build and load balancer url when its prod build

    then copy the url form loadbalancer and open it in browser, you should see web page.

157)Development vs Prod

    here we saw that in react we have different Dockerfile for dev and prod.and end point to bacekdn code diffres.
    for node code, we connect to difdrent db, in dev and prod.

    so we might thing that it is not one ans same env and we lost the benefits of docker. but this is not the case, in recat's
    case diffren files are needed because build dtep is required, react forces us. and end points nedds to be diffrentnt. but
    we ca see that in dev and prod we are using same version of node.

    same goes for backend even db is diffrent, runtime and code is locked in image. then we run image in dev and prod.
    we do not want to use same db in dev and prod.


158)Understanding multi-stage builds
    we build the whole dockerFile in multistage , but a smentioned in leture 155, we can also target induival stages. -

    docker build --target "stageName" -f frontend/Dockerfile.prod ./frontend

    docker build --target "stageName" -f frontend/Dockerfile.prod ./frontend

    this would cause the image build process to stop after this stage was processed.

    this will be helpful when you have multistages ,Let's say one stage for testing,one stage for running a server.
    And sometimes you just wanna run up to the tests.Sometimes you also wanna run up to the server.

    see Dockerfile.prod to see how we can give name to build stages.


159)Beyond AWS
    here we saw AWS but you can use any other c;oud services also.

     I wanted to show you potential challenges what to keep in mind and how certain features we saw locally with Docker and Docker
     compose can be translated to manage services.Therefore what you learned here should not just help you with AWS,but with any
     provider since you already are aware of a couple of approaches and pin points,you might be using and facing when deploying 
     containers.

160)Summary 

    what we covered -

        1)deployment on -
            a)remote amchine where you need to do everything like installing docker then downloading image.
            b)managed approach like ECS
        2)bind mounts are primarily for local setup to mirror our live code into container.
        3)for applications that need build step, we saw multistage build step
        4)deploying multiple containers in same task and in diffrent tasks(diffret URL's)
        5)tradeoff's between more control and responsibilities vs having less. 2 approachs(slide 10) -
        6)same thing in databses (slide 11).And that there, again, we have this trade-off,we can deploy our own database containers,
            but then we also have to manage them.And there are aspects like performance, scaling,availability, but also backups 
            and security,which can be challenging.

            That's why I also recommended that you at least consider moving to a managed database service


To be looked into -

https://www.udemy.com/course/docker-kubernetes-the-practical-guide/learn/lecture/22626711#questions/13989812


my Question -

https://www.udemy.com/course/docker-kubernetes-the-practical-guide/learn/lecture/22626711#questions/18307506

ipc 
subnets
security groups - exposes a specific ports, inbound-outbound rules are defined.
target group name - after selecting load balancer while configuring a service, we need this.
    




    