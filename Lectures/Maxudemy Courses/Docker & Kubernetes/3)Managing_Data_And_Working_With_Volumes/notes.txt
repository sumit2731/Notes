Module content -
    a)diffrent types of data in images And Containers
    b)dive into concept called volumne
    c)arguments and envirenment variables.

a)Volumes & Bind Mounts -

    Annpnymous volumes -

        1)path in local file system is mapped to some path in docker. we do not have access to that path in our local file system.
        2)annonymous volume is deleted, container is removed.This is because annonymous volume is linked to container, when conatiner
            is removed this is also delted.
        3)2 ways to setup annonymous volumes
            a)via docker config file,see config file of code1.
            b)via -v flag while running the container -
                -v /app/node_modules

        4)uses -
            a)we can tell Docker that there are certain parts in its internal file system, which should not be overwritten
                from outside, in case where both bind mount and docker have data. see lecture 53, slide 5.this lectures also
                explains how docker handles clashes between different volumes i.e when diffrent bindmounts and volumes point
                to same path inside docker.more specifci path wins.

            b)anonymous volumes also still create a counterpart, a folder, on your host machine.Of course that's removed when the 
            container's removed,but that exists as long as the container is running.And that of course means that docker doesn't have
            to store all the data inside of the container and doesn't have to manage all the data inside of this container read write
            layer.But that instead it can outsource certain data to your host machine file system.And this can also help with 
            performance and efficiency.So that's why anonymous modules can be worth a closer look.

    Named Volume -

        1)same as annonymous volume except that volume is not deleted when container is removed. so this can be used to persistent data
            between container shutdowns.
        2)named volume cannot be created via dockerFile, they need to be created via cmd when starting the container.

            docker run -d -p 3000:80 --rm --name feedback-app -v nameOfVolume:/app/feedback nameOfVolume.

            see config file of code2.

        3)uses -
            stores data that need to be persistent even when container dies i.e can be shared across containers. like -

                1)DB files.
                2)cahed files


    Bind mounts -

        1)we map a path on local file system with path in container.
        2)so we can access the path in local file system also.data survives the container shutdown.
        3)uses - you can edit the data in local file system and chnages will be avalible inside docker and vice versa. ex -

            1)hot reloading in dev env.
            2)accessing logs file outside container.

        4)how to use it -

            docker run 
                -v feedback:/app/feedback 
                -v "/Users/susood/Desktop/notes/notes/Lectures/Maxudemy Courses/Docker & Kubernetes/3)Managing_Data_And_Working_With_Volumes/code2:/app" 
                feedback-node

            "" are used so that command does not break in case our code contains special chracters and white spaces.
            shortcuts for filling current directory path - https://www.udemy.com/course/docker-kubernetes-the-practical-guide/learn/lecture/23074506#overview

            also make sure that docker has access to folder where bind mount is getting created. see 06:68 of lecture 51.


b)using nodemon to restart server when js files chnages. lecture - 54.


Code -
    Code 1 - annonymous volumes
    Code 2 - Named Volume, Bind Mount and use of annonymous volume

Important Concepts -
    Lecture 53 - How we can use annonymous volumes to prevent overwriting of some folder in docker file system

Opeating system Diffrences -
    a)For using bind mounts, docker needs to have access to local file system,lecture 51.
    b)for nodemon to pick changes, files should be stored inside, lecture 54.


Lectures 56(Look at Read-Only Volume) -
    intention of usng bind mount was that we want to change code in our local and it should reflect in container. so we can mark this volume
    as read only so that we do not accidantly chnage anything from container. but we need write permission for feedback and temp folder.earlier
    we ran this command -

    docker run -d --rm -p 3000:80 --name feedback-app -v feedback:/app/feedback -v "$(pwd):/code3:/app" -v /app/node_modules feedback-node

    now we want to block write access of docker for bind mount. but provide write access for feedback and temp. so there we ca use strategy
    that we alraedy used i.e map annonymous volume to these locations and there use more specific path.with feedback we have already attached
    named volumne, so there adding we have write access, we just need to add annonymous volume for temp folder. so now we ran -

    docker run -d --rm -p 3000:80 --name feedback-app -v feedback:/app/feedback -v "$(pwd):/app:ro" -v /app/node_modules -v /app/temp feedback-node



Lecture 57(managing docker volumes)

    here we saw basic commands to manage docker volumes. commands are listed in main notes.

lecture 58(using "COPY" vs Bind Mounts) -

    here we saw that why do we need copy command in Dockerfile, when we have bind mount. reason for this is bind mount
    is good for development but while deploying contianer we do not want to chabge files on the fly. so that is why we
    want to have snapshot of code in image. while spinning up the contianer we may use bind mount otherwise we can 
    directly go for deployemnt.

59)(dont copy everything)

    we can add a dockerignore file, there we can mention files that should'nt be copied when we use '.' in copy command.
    for example we do want to copy node_modules form local system to image.

61)Arguments & Envirenment variables
    see slide 8. see code4

    first we added a envirement variable. in DockerFile -
        
        ENV PORT 80
        ENV PORT2 81

        so this is default value of PORT variable. anywhere in dockerFile we can refer to this varible by $PORT. now we
        can also overwrite value of these envirement variables at run time by passing explicit values -
        
        a)env variables are added while creating container through --env or -e flag. they can be used in Dockerfile by $Name. In code 
            base how to access them depends upon language to language. but in nodejs we can access hem by -
            
            process.env.nameofvariable.

            earlier we created container by- 
                docker run -d --rm -p 3000:80 --name feedback-app -v feedback:/app/feedback -v "$(pwd):/app:ro" -v /app/node_modules -v /app/temp feedback-node

            now we just added a env variable by adding --env flag -
                docker run -d --rm -p 3000:8000 --name feedback-app -v feedback:/app/feedback -v "$(pwd):/app:ro" -v /app/node_modules -v /app/temp --env PORT=8000 feedback-node:env

            then we used this varible in DockerFile and server,js file.

            ways to pass multiple env variables -
                --env PORT=8000 --env name=abc
                            or
                -e PORT=8000 --env name=abc

        b)also we can add env variables in file. then use this flag -
            --env-file "relative path of file"

             --env-file ./.env


lecture 62 - it is text read it

lecture 63(Using build arguments) -

    see code 4. here we use build time arguments to pass defualt value of port while creating the image, instead of hardcoding it in Dockerfile.
     argument cannot be used in code, it is only avalible in docker file.

     so we define a argument in DockerFile. and provide value for it while creating the image.

     docker build -t feedback-node:dev --build-arg DEFAULT_PORT=8000


     Now one note about where you specify args and envs.You might of course wanna place arg and envin a place where you then need it thereafter,
        and not place it right at the beginning of your Dockerfile because these instructions just like all other instructions, add layers to your
        Dockerfile.And hence, when something changes about them, all subsequent layers are rebuilt, are re-executed.And I don't wanna 
        execute npm install again all the time.Just because I passed in a different default port argument.It's not relevant to this command.

    so we moved them after NPM install command.